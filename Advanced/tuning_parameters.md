##### 超参数调优方法

贝叶斯优化

- 贝叶斯优化已成为机器学习算法超参数调整的有效工具，更具体地说，适用于深度神经网络等复杂模型。
- 它提供了一个有效的框架来优化昂贵的黑盒功能，而无需知道它的形式。它已应用于多个领域，包括学习最优机器人力学、序列实验设计和合成基因设计。

遗传算法

- 遗传算法 (EA) 是一种优化算法，它通过根据称为算子的某些规则修改一组候选解决方案（种群）来工作。
- EA 的主要优势之一是它们的通用性：这意味着 EA 可以在广泛的条件下使用，因为它们简单且独立于潜在问题。在超参数调整问题中，遗传算法已被证明比基于精度/速度的网格搜索技术表现更好。

梯度优化

- 基于梯度的优化是一种优化多个超参数的方法，基于机器学习模型选择标准相对于超参数的梯度计算。
- 当满足训练标准的一些可微性和连续性条件时，可以应用这种超参数调整方法。

网格搜索

- 网格搜索是超参数调优的基本方法。它对用户指定的超参数集执行详尽的搜索。这种方法是最直接的导致最准确的预测。
- 使用这种调优方法，用户可以找到最佳组合。网格搜索适用于几个超参数，但是搜索空间有限。

随机搜索

- 随机搜索可以说是对网格搜索的基本改进。该方法是指对可能参数值的某些分布的超参数进行随机搜索。
- 搜索过程继续进行，直到达到所需的精度。随机搜索类似于网格搜索，但已证明比后者创建更好的结果。
- 该方法通常被用作 HPO 的基线来衡量新设计算法的效率。尽管随机搜索比网格搜索更有效，但它仍然是一种计算密集型方法


Keras Tuner

- Keras Tuner是一个库，允许用户为机器学习或深度学习模型找到最佳超参数。
- 该库有助于查找内核大小、优化学习率和不同的超参数。Keras Tuner可用于为各种深度学习模型获取最佳参数，以实现最高精度。

种群优化

- 基于种群的方法本质上是一系列基于随机搜索（如遗传算法）的方法。
- 最广泛使用的基于种群的方法之一是 DeepMind 提出的基于种群的训练（PBT）。PBT在两个方面，是一种独特的方法：
- 它允许在训练期间使用自适应超参数
- 它结合了并行搜索和顺序优化

ParamILS

- ParamILS（参数配置空间中的迭代局部搜索）是一种用于自动算法配置的通用随机局部搜索方法。ParamILS 是一种自动算法配置方法，有助于开发高性能算法及其应用程序。
- ParamILS 使用默认和随机设置进行初始化，并采用迭代第一改进作为辅助本地搜索过程。它还使用固定数量的随机移动来进行扰动，并且总是接受更好或同样好的参数配置，但会随机重新初始化搜索。
