- 梯度下降算法
  - 全量梯度下降，也即对所有的训练数据计算损失并进行梯度反向传播，这样会导致计算开销大，从而使得模型的推理速度变慢很多
  - 小批量随机梯度下降，对每一个小批量内的数据计算损失并进行梯度反向传播，这样可以使用矩阵计算加速并行，引入随机性可以避免困在局部最优解
- 常用的优化更新策略
  - 动量更新
